
import os
import streamlit as st

# Optional: pandas only if you want to demo tables later
try:
    import pandas as pd  # noqa: F401
except Exception:
    pass

st.set_page_config(page_title="SsamM_test1 - Gemini Demo", page_icon="âœ¨", layout="wide")
st.title("âœ¨ Gemini API ì—°ë™ Streamlit ë°ëª¨")

st.write("GitHub â†’ Streamlit ë°°í¬ + **Google Gemini** API ì—°ë™ ì˜ˆì‹œì…ë‹ˆë‹¤. "
         "ì¢Œì¸¡ì—ì„œ íŒŒë¼ë¯¸í„°ë¥¼ ì„¤ì •í•˜ê³  í”„ë¡¬í”„íŠ¸ë¥¼ ë³´ë‚´ë³´ì„¸ìš”.")

# ---------------- Sidebar ----------------
with st.sidebar:
    st.header("âš™ï¸ Settings")
    model = st.selectbox(
        "Model",
        ["gemini-1.5-flash", "gemini-1.5-pro"],
        index=0
    )
    temperature = st.slider("temperature", 0.0, 2.0, 0.7, 0.1)
    max_output_tokens = st.slider("max_output_tokens", 64, 4096, 512, 64)
    st.markdown("---")
    api_key = os.getenv("GOOGLE_API_KEY", "")
    if api_key:
        st.success("GOOGLE_API_KEY: ê°ì§€ë¨ âœ…")
    else:
        st.warning("GOOGLE_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤. ë°°í¬ ì „ Streamlit Secretsì— ì¶”ê°€í•˜ì„¸ìš”.")

# ---------------- Tabs ----------------
tab1, tab2 = st.tabs(["ğŸ“ Text Generation", "ğŸ§ª Prompt Playground"])

# Utility: lazy import for the SDK (avoids import errors before requirements installed)
def get_gemini_client():
    import google.generativeai as genai
    genai.configure(api_key=api_key)
    return genai

# ---- Tab1: simple text generation
with tab1:
    st.subheader("ğŸ“ í”„ë¡¬í”„íŠ¸ â†’ í…ìŠ¤íŠ¸ ìƒì„±")
    prompt = st.text_area(
        "í”„ë¡¬í”„íŠ¸ ì…ë ¥",
        value="ì„œìš¸ì˜ ì£¼ë§ ë‚ ì”¨ë¥¼ ì¹œê·¼í•œ í†¤ìœ¼ë¡œ 3ë¬¸ì¥ ìš”ì•½í•´ì¤˜ (ì˜ˆì‹œ).",
        height=140
    )
    if st.button("Generate", key="gen1"):
        if not api_key:
            st.error("GOOGLE_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤. ì¢Œì¸¡ ì•ˆë‚´ë¥¼ ì°¸ê³ í•´ Secretsì— ì¶”ê°€í•œ ë’¤ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
        else:
            try:
                genai = get_gemini_client()
                generation_config = {
                    "temperature": temperature,
                    "max_output_tokens": max_output_tokens,
                }
                model_obj = genai.GenerativeModel(model_name=model, generation_config=generation_config)
                with st.spinner("ëª¨ë¸ í˜¸ì¶œ ì¤‘â€¦"):
                    response = model_obj.generate_content(prompt)
                if response and response.text:
                    st.success("âœ… ì‘ë‹µ ìˆ˜ì‹ ")
                    st.markdown(response.text)
                else:
                    st.warning("ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            except Exception as e:
                st.exception(e)

# ---- Tab2: system style + history (basic chat-like)
with tab2:
    st.subheader("ğŸ§ª ì‹œìŠ¤í…œ ìŠ¤íƒ€ì¼ + ëŒ€í™”í˜• í…ŒìŠ¤íŠ¸")
    system_instruction = st.text_area(
        "System Instruction (ì„ íƒ)",
        value="You are a helpful assistant for English speaking practice. Respond briefly unless asked for details.",
        height=100
    )
    user_input = st.text_area("User Message", value="ì—¬í–‰ ì˜ì–´ íšŒí™”ì—ì„œ ê³µí•­ ì²´í¬ì¸ ìƒí™©ì„ 5ë¬¸ì¥ìœ¼ë¡œ ì—­í• ê·¹ í˜•íƒœë¡œ ë§Œë“¤ì–´ì¤˜.", height=130)
    col_a, col_b = st.columns(2)
    with col_a:
        keep_history = st.checkbox("íˆìŠ¤í† ë¦¬ ìœ ì§€(ê°„ë‹¨)", value=True)
    with col_b:
        clear = st.button("ëŒ€í™” ì´ˆê¸°í™”")

    if "chat_history" not in st.session_state or clear:
        st.session_state.chat_history = []

    if st.button("Send", key="gen2"):
        if not api_key:
            st.error("GOOGLE_API_KEYê°€ ì—†ìŠµë‹ˆë‹¤. ì¢Œì¸¡ ì•ˆë‚´ë¥¼ ì°¸ê³ í•´ Secretsì— ì¶”ê°€í•œ ë’¤ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")
        else:
            try:
                genai = get_gemini_client()
                generation_config = {
                    "temperature": temperature,
                    "max_output_tokens": max_output_tokens,
                }
                # Build messages: Gemini SDK uses content parts. We'll just join for simplicity.
                messages = []
                if system_instruction.strip():
                    messages.append({"role": "user", "parts": [f"[SYSTEM]: {system_instruction.strip()}"]})
                # past messages
                if keep_history and st.session_state.chat_history:
                    messages.extend(st.session_state.chat_history)
                messages.append({"role": "user", "parts": [user_input]})

                model_obj = genai.GenerativeModel(model_name=model, generation_config=generation_config)
                with st.spinner("ëª¨ë¸ í˜¸ì¶œ ì¤‘â€¦"):
                    # Use responses API for multi-turn by passing history as 'contents'
                    response = model_obj.generate_content(contents=messages)
                text = getattr(response, "text", None)
                if text:
                    st.session_state.chat_history = messages + [{"role": "model", "parts": [text]}]
                    st.success("âœ… ì‘ë‹µ ìˆ˜ì‹ ")
                    st.markdown(text)
                else:
                    st.warning("ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            except Exception as e:
                st.exception(e)

st.markdown("---")
st.caption("â“’ 2025 SsamM_test1 - Streamlit + Gemini Demo")
